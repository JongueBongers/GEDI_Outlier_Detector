{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a187ba289f38e07b",
   "metadata": {},
   "source": [
    "# Opening HDF5 Files\n",
    "This tests the ability to open an HDF5 file using for-loops. I also converted the contents of the HDF5 file to a dictionary and printed the summary of the dictionary to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T17:51:58.952874Z",
     "start_time": "2024-07-16T17:51:58.376788Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15d26e4e0a7bba0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T17:51:58.958253Z",
     "start_time": "2024-07-16T17:51:58.952874Z"
    }
   },
   "outputs": [],
   "source": [
    "# filenames = ['GEDI_sample_files/GEDI01_B_2022004042652_O17343_04_T10772_02_005_02_V002.h5',\n",
    "#              'GEDI_sample_files/GEDI01_B_2022207041426_O20491_04_T09293_02_005_03_V002.h5',\n",
    "#              'GEDI_sample_files/GEDI02_A_2021050140102_O12405_02_T10912_02_003_02_V002.h5',\n",
    "#              'GEDI_sample_files/GEDI02_A_2021086153349_O12964_03_T08275_02_003_02_V002.h5',\n",
    "#              'GEDI_sample_files/GEDI04_A_2021009022644_O11762_03_T01637_02_002_02_V002.h5',\n",
    "#              'GEDI_sample_files/GEDI04_A_2022106075705_O18927_04_T10647_02_003_01_V002.h5']\n",
    "\n",
    "filenames = ['GEDI_sample_files/GEDI02_A_2021050140102_O12405_02_T10912_02_003_02_V002.h5',\n",
    "             'GEDI_sample_files/GEDI02_A_2021086153349_O12964_03_T08275_02_003_02_V002.h5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ccae5c15bda0fd0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T17:51:58.968452Z",
     "start_time": "2024-07-16T17:51:58.958253Z"
    }
   },
   "outputs": [],
   "source": [
    "def print_group_contents(group, indent=0):\n",
    "    for key in group:\n",
    "        item = group[key]\n",
    "        print(\"  \" * indent + f\"{key}: {'Group' if isinstance(item, h5py.Group) else 'Dataset'}\")\n",
    "        if isinstance(item, h5py.Group):\n",
    "            print_group_contents(item, indent + 1)\n",
    "        else:\n",
    "            print(\"  \" * (indent + 1) + f\"Shape: {item.shape}, Type: {item.dtype}\")\n",
    "\n",
    "def save_group_contents(group, indent=0, file=None):\n",
    "    \"\"\"\n",
    "    Recursively saves the contents of an h5 group to a file.\n",
    "    \"\"\"\n",
    "    for key in group:\n",
    "        item = group[key]\n",
    "        line = \"  \" * indent + f\"{key}: {'Group' if isinstance(item, h5py.Group) else 'Dataset'}\\n\"\n",
    "        file.write(line)\n",
    "        if isinstance(item, h5py.Group):\n",
    "            save_group_contents(item, indent + 1, file)\n",
    "        else:\n",
    "            file.write(\"  \" * (indent + 1) + f\"Shape: {item.shape}, Type: {item.dtype}\\n\")\n",
    "            data_preview = item[:10]  # Get the first 10 values\n",
    "            file.write(\"  \" * (indent + 1) + f\"First 10 values: {data_preview}\\n\")\n",
    "            \n",
    "# def save_rh_contents(group, indent=0, file=None):\n",
    "#     \"\"\"\n",
    "#     Recursively saves the contents of an h5 group to a file.\n",
    "#     \"\"\"\n",
    "#     for key in group:\n",
    "#         item = group[key]\n",
    "#         line = \"  \" * indent + f\"{key}: {'Group' if isinstance(item, h5py.Group) else 'Dataset'}\\n\"\n",
    "#         file.write(line)\n",
    "#         if isinstance(item, h5py.Group):\n",
    "#             save_group_contents(item, indent + 1, file)\n",
    "#         else:\n",
    "#             file.write(\"  \" * (indent + 1) + f\"Shape: {item.shape}, Type: {item.dtype}\\n\")\n",
    "#             if key == 'rh':\n",
    "#                 rh_98 = item[98]\n",
    "#                 rh_50 = item[50]\n",
    "#                 file.write(\"  \" * (indent + 1) + f\"RH98 values: {rh_98}\\n\" + f\"RH50 values: {rh_50}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6efeebd9134b8eda",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T17:52:50.152984Z",
     "start_time": "2024-07-16T17:52:09.108959Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: GEDI_sample_files/GEDI02_A_2021050140102_O12405_02_T10912_02_003_02_V002.h5Keys: <KeysViewHDF5 ['BEAM0000', 'BEAM0001', 'BEAM0010', 'BEAM0011', 'BEAM0101', 'BEAM0110', 'BEAM1000', 'BEAM1011', 'METADATA']>\n",
      "File: GEDI_sample_files/GEDI02_A_2021086153349_O12964_03_T08275_02_003_02_V002.h5Keys: <KeysViewHDF5 ['BEAM0000', 'BEAM0001', 'BEAM0010', 'BEAM0011', 'BEAM0101', 'BEAM0110', 'BEAM1000', 'BEAM1011', 'METADATA']>\n"
     ]
    }
   ],
   "source": [
    "# output_file_path = 'GEDI_outputs/printed_sample_contents.txt'\n",
    "output_file_path = 'GEDI_outputs/printed_rh_contents.txt'\n",
    "\n",
    "with open(output_file_path, 'w') as output_file:\n",
    "    for filename in filenames:\n",
    "        with h5py.File(filename, 'r') as f:\n",
    "            print(\"File: \" + filename + \"Keys: %s\" % f.keys())\n",
    "            output_file.write(\"File:\" + filename + \"\\n\" + \"Keys: %s\\n\" % f.keys())\n",
    "            for name in f:\n",
    "                if isinstance(f[name], h5py.Group):\n",
    "                    output_file.write(f\"Group: {name}\\n\")\n",
    "                else:\n",
    "                    output_file.write(f\"Dataset: {name}\\n\")\n",
    "                to_save = f[name]\n",
    "                save_group_contents(to_save, indent=1, file=output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5b8ea66ad13292d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T18:44:44.040088Z",
     "start_time": "2024-07-10T18:44:44.026873Z"
    }
   },
   "outputs": [],
   "source": [
    "def h5_to_dict(group):\n",
    "    \"\"\"\n",
    "    Recursively converts an h5 group into a dictionary of Numpy arrays.\n",
    "    \"\"\"\n",
    "    data_dict = {}\n",
    "    for key in group:\n",
    "        item = group[key]\n",
    "        if isinstance(item, h5py.Group):\n",
    "            data_dict[key] = h5_to_dict(item)  # Recursively handle nested groups\n",
    "        else:\n",
    "            data_dict[key] = item[:]  # Convert dataset to numpy array\n",
    "    return data_dict\n",
    "\n",
    "def print_dict_summary(data_dict, indent=0, file=None):\n",
    "    \"\"\"\n",
    "    Recursively prints the summary of a dictionary of Numpy arrays to a file.\n",
    "    \"\"\"\n",
    "    for key, value in data_dict.items():\n",
    "        if isinstance(value, dict):\n",
    "            file.write(\"  \" * indent + f\"Group: {key}\\n\")\n",
    "            print_dict_summary(value, indent + 1, file=file)\n",
    "        else:\n",
    "            file.write(\"  \" * indent + f\"Dataset: {key}, Shape: {value.shape}, Type: {value.dtype}\\n\")\n",
    "\n",
    "def verify_specific_datasets(data_dict):\n",
    "    \"\"\"\n",
    "    Access and print specific datasets in the dictionary for verification.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        data_array = data_dict['group1']['dataset1']\n",
    "        print(f\"\\nVerifying 'group1/dataset1':\")\n",
    "        print(f\"Shape: {data_array.shape}\")\n",
    "        print(f\"Type: {data_array.dtype}\")\n",
    "        print(f\"First 10 values: {data_array[:10]}\")\n",
    "        \n",
    "    except KeyError as e:\n",
    "        print(f\"KeyError: {e} - Ensure the specified path exists in the dictionary.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a69679d89625f291",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T18:48:44.423062Z",
     "start_time": "2024-07-10T18:46:45.878410Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting GEDI_sample_files/GEDI01_B_2022004042652_O17343_04_T10772_02_005_02_V002.h5 to a dictionary...\n",
      "  Working on group: BEAM0000...\n",
      "  Working on group: BEAM0001...\n",
      "  Working on group: BEAM0010...\n",
      "  Working on group: BEAM0011...\n",
      "  Working on group: BEAM0101...\n",
      "  Working on group: BEAM0110...\n",
      "  Working on group: BEAM1000...\n",
      "  Working on group: BEAM1011...\n",
      "  Working on group: METADATA...\n",
      "KeyError: 'group1' - Ensure the specified path exists in the dictionary.\n",
      "Converting GEDI_sample_files/GEDI01_B_2022207041426_O20491_04_T09293_02_005_03_V002.h5 to a dictionary...\n",
      "  Working on group: BEAM0000...\n",
      "  Working on group: BEAM0001...\n",
      "  Working on group: BEAM0010...\n",
      "  Working on group: BEAM0011...\n",
      "  Working on group: BEAM0101...\n",
      "  Working on group: BEAM0110...\n",
      "  Working on group: BEAM1000...\n",
      "  Working on group: BEAM1011...\n",
      "  Working on group: METADATA...\n",
      "KeyError: 'group1' - Ensure the specified path exists in the dictionary.\n",
      "Converting GEDI_sample_files/GEDI02_A_2021050140102_O12405_02_T10912_02_003_02_V002.h5 to a dictionary...\n",
      "  Working on group: BEAM0000...\n",
      "  Working on group: BEAM0001...\n",
      "  Working on group: BEAM0010...\n",
      "  Working on group: BEAM0011...\n",
      "  Working on group: BEAM0101...\n",
      "  Working on group: BEAM0110...\n",
      "  Working on group: BEAM1000...\n",
      "  Working on group: BEAM1011...\n",
      "  Working on group: METADATA...\n",
      "KeyError: 'group1' - Ensure the specified path exists in the dictionary.\n",
      "Converting GEDI_sample_files/GEDI02_A_2021086153349_O12964_03_T08275_02_003_02_V002.h5 to a dictionary...\n",
      "  Working on group: BEAM0000...\n",
      "  Working on group: BEAM0001...\n",
      "  Working on group: BEAM0010...\n",
      "  Working on group: BEAM0011...\n",
      "  Working on group: BEAM0101...\n",
      "  Working on group: BEAM0110...\n",
      "  Working on group: BEAM1000...\n",
      "  Working on group: BEAM1011...\n",
      "  Working on group: METADATA...\n",
      "KeyError: 'group1' - Ensure the specified path exists in the dictionary.\n",
      "Converting GEDI_sample_files/GEDI04_A_2021009022644_O11762_03_T01637_02_002_02_V002.h5 to a dictionary...\n",
      "  Working on group: ANCILLARY...\n",
      "  Working on group: BEAM0000...\n",
      "  Working on group: BEAM0001...\n",
      "  Working on group: BEAM0010...\n",
      "  Working on group: BEAM0011...\n",
      "  Working on group: BEAM0101...\n",
      "  Working on group: BEAM0110...\n",
      "  Working on group: BEAM1000...\n",
      "  Working on group: BEAM1011...\n",
      "  Working on group: METADATA...\n",
      "KeyError: 'group1' - Ensure the specified path exists in the dictionary.\n",
      "Converting GEDI_sample_files/GEDI04_A_2022106075705_O18927_04_T10647_02_003_01_V002.h5 to a dictionary...\n",
      "  Working on group: ANCILLARY...\n",
      "  Working on group: BEAM0000...\n",
      "  Working on group: BEAM0001...\n",
      "  Working on group: BEAM0010...\n",
      "  Working on group: BEAM0011...\n",
      "  Working on group: BEAM0101...\n",
      "  Working on group: BEAM0110...\n",
      "  Working on group: BEAM1000...\n",
      "  Working on group: BEAM1011...\n",
      "  Working on group: METADATA...\n",
      "KeyError: 'group1' - Ensure the specified path exists in the dictionary.\n"
     ]
    }
   ],
   "source": [
    "data_dicts = []\n",
    "summary_file_path = 'GEDI_outputs/sample_dict_summaries.txt'\n",
    "\n",
    "with open(summary_file_path, 'w') as summary_file:\n",
    "    for filename in filenames:\n",
    "        # Open the .h5 file in read mode and convert it to a dictionary\n",
    "        print(f\"Converting {filename} to a dictionary...\")\n",
    "        with h5py.File(filename, 'r') as h5_file:\n",
    "            data_dict = {}\n",
    "            for group_name in h5_file:\n",
    "                print(f\"  Working on group: {group_name}...\")\n",
    "                group = h5_file[group_name]\n",
    "                data_dict[group_name] = h5_to_dict(group)\n",
    "        \n",
    "            # Write the summary to the file\n",
    "            summary_file.write(f\"Summary of the converted dictionary {filename} :\\n\")\n",
    "            print_dict_summary(data_dict, file=summary_file)\n",
    "            data_dicts.append(data_dict)\n",
    "            verify_specific_datasets(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "accb6d53c7011c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T18:51:09.103001Z",
     "start_time": "2024-07-10T18:51:09.080136Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "print(len(data_dicts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e81f41774c454fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
